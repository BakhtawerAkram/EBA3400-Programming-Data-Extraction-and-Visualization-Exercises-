<h2>EBA3400 Exercise Set 9: Introduction to Pandas</h2>

<h3>9.1 Create own data frames</h3>

Given the lists

list_m_zip = [1524,105,5005,1760,7003,3725,9505]
list_m_name = ['Moss','Oslo','Bergen','Halden','Trondheim','Skien','Alta']
list_m_county = [1,3,12,1,50,8,20]
list_c_county = [1,2,3,4,5,6,7,8,9,10,11,12,14,15,50,18,19,20]
list_c_name = ['Østfold','Akershus','Oslo','Hedmark','Oppland','Buskerud','Vestfold','Telemark','Aust-Agder',
               'Vest-Agder','Rogaland','Hordaland','Sogn og Fjordane','Møre og Romsdal','Trøndelag',
               'Nordland','Troms','Finnmark']

Create three different data frames
- 1 A dataset containing the first five municipality records
- 2 A dataset containing the last two municipality records
- 3 A dataset containing all counties

import pandas as pd

municipality = list(zip(list_m_zip,list_m_name,list_m_county))
dfm = pd.DataFrame(municipality, columns = ['Zipcode', 'Municipality', 'County Code'])
dfm5 = dfm[:5].copy()
dfm5

dfm2 = dfm[5:].copy()
dfm2

county = list(zip(list_c_county, list_c_name))
dfc = pd.DataFrame(county, columns = ['County Code', 'County'])
dfc

<h3>9.2 Concatenate and merge</h3>

Perform the following tasks using the data from Exercise 9.1. First, concatenate dataset 1 and dataset 2. Second, merge the concatenated dataset with the dataset containing all counties. You should merge on county code.

dfm_new = pd.concat([dfm5,dfm2],axis=0)
dfm_new

merge = pd.merge(dfm_new, dfc, how='inner', on='County Code')
merge 

<h3>9.2 Brand sales at online e-tailer</h3>

In this exercise we will investigate the brand sales of an online retailer of mens clothing. The company operates in the mid to high end segment, offering a wide range of items and brands to their customers via online solutions. You are asked to perform the following tasks:

- A Import the dataset fashion.csv. Use the date column as the index and make sure to parse the dates on import.
- B Summarise data by year (hint: add a year column)
- C What is the largest monthly sales by brand and year?

<h4>Part A</h4>

df = pd.read_csv('C:/Users/power/OneDrive/Documents/Programming/Data/fashion.csv', parse_dates = ['Date'], index_col = 'Date')

<h4>Part B</h4>

df['Year'] = df.index.year
df.groupby(['Year']).sum()

<h4>Part C</h4>

#df['Month'] = df.index.month
df_largest = df.groupby('Year').max()
df_largest

#OR just:
#df.groupby('Year').max()

<h3>9.3 US National Parks and their animal and plant species</h3>

The National Park Service publishes a database of animal and plant species identified in individual national parks and verified by evidence — observations, vouchers, or reports that document the presence of a species in a park. All park species records are available to the public on the National Park Species portal; exceptions are made for sensitive, threatened, or endangered species when widespread distribution of information could pose a risk to the species in the park.

National Park species lists provide information on the presence and status of species in US national parks. These species lists are works in progress and the absence of a species from a list does not necessarily mean the species is absent from a park. The time and effort spent on species inventories varies from park to park, which may result in data gaps. Species taxonomy changes over time and reflects regional variations or preferences; therefore, records may be listed under a different species name.

Each park species record includes a species ID, park name, taxonomic information, scientific name, one or more common names, record status, occurrence (verification of species presence in park), nativeness (species native or foreign to park), abundance (presence and visibility of species in park), seasonality (season and nature of presence in park), and conservation status (species classification according to US Fish & Wildlife Service). Taxonomic classes have been translated from Latin to English for species categorization; order, family, and scientific name (genus, species, subspecies) are in Latin.

In this exerciese you are asked to do the following. 

- A First import data on US parks (parks.csv)
- B How many acres of national parks are there per state in the US? Make a top 5 list. 
- C Do you see any problems with the data quality here?
- D Import data on species (species.csv)
- E Create a subset of the data consisting of 'Park Name', 'Common Names', 'Family', 'Occurrence', 'Nativeness' and 'Abundance'
- F How many species are there per national park? Which park has the most species? Make a top 10 and bottom 10 list.
- G Merge the park data with the species data. Merge on Park Name. Verify that the merged data look OK by inspecting records [0,100,5000,10000,35000,50000,70000,100000]

<h4>Part A</h4>

parks = pd.read_csv('C:/Users/power/OneDrive/Documents/Programming/Data/parks.csv')
parks.head(5)

<h4>Part B</h4>

# acres of land by state
parks.groupby(['State']).sum()

<h4>Part C</h4>

Make comment here.

<h4>Part D</h4>

species = pd.read_csv('C:/Users/power/OneDrive/Documents/Programming/Data/species.csv')
species.head(3)

<h4>Part E</h4>

species_sub = species[['Park Name', 'Common Names', 'Family', 'Occurrence', 'Nativeness', 'Abundance']]

<h4>Part F</h4>

pr_park = species_sub['Park Name'].value_counts()
top10 = pr_park[:10]
bottom10 = pr_park[-10:]

print('___________________________________________________')
print('The top 10 National Parks by Species:')
print('___________________________________________________')
print(top10)
print('\n')
print('___________________________________________________')
print('The bottom 10 National Parks by Species')
print('___________________________________________________')
print(bottom10)

<h4>Part G</h4>

park_species_data = pd.merge(species_sub,parks,how='inner',on='Park Name')
park_species_data.iloc[[0,100,5000,10000,35000,50000,70000,100000]]
